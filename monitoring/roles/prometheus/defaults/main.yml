---
prometheus_version: 2.47.0
prometheus_binary_local_dir: ''
prometheus_binary_url: "https://github.com/{{ _prometheus_repo }}/releases/download/v{{ prometheus_version }}/\
                        prometheus-{{ prometheus_version }}.linux-{{ go_arch }}.tar.gz"
prometheus_checksums_url: "https://github.com/{{ _prometheus_repo }}/releases/download/v{{ prometheus_version }}/sha256sums.txt"
prometheus_skip_install: false

prometheus_config_dir: /etc/prometheus
prometheus_db_dir: /var/lib/prometheus
prometheus_read_only_dirs: []

prometheus_web_listen_address: "0.0.0.0:9090"
prometheus_web_external_url: ''
prometheus_metrics_path: "/{{ (prometheus_web_external_url + '/metrics') | regex_replace('^(.*://)?(.*?)/') }}"
# See https://github.com/prometheus/exporter-toolkit/blob/master/docs/web-configuration.md
prometheus_web_config:
  tls_server_config: {}
  http_server_config: {}
  basic_auth_users: {}

prometheus_storage_retention: "30d"
# Available since Prometheus 2.7.0
# [EXPERIMENTAL] Maximum number of bytes that can be stored for blocks. Units
# supported: KB, MB, GB, TB, PB.
prometheus_storage_retention_size: "0"

# The Agent mode optimizes Prometheus for the remote write use case: https://prometheus.io/blog/2021/11/16/agent/
prometheus_agent_mode: false

prometheus_config_flags_extra: {}
# prometheus_config_flags_extra:
#   storage.tsdb.retention: 15d
#   alertmanager.timeout: 10s

prometheus_alertmanager_config:
   - scheme: http
#     path_prefix: alertmanager/
#     basic_auth:
#       username: user
#       password: pass
     static_configs:
       - targets: ["127.0.0.1:9093"]

prometheus_alert_relabel_configs: []
# prometheus_alert_relabel_configs:
#   - action: labeldrop
#     regex: replica

prometheus_global:
  scrape_interval: 15s
  scrape_timeout: 10s
  evaluation_interval: 15s

prometheus_remote_write: []
# prometheus_remote_write:
#   - url: https://dev.kausal.co/prom/push
#     basic_auth:
#       password: FOO

prometheus_remote_read: []
# prometheus_remote_read:
#   - url: https://prometheus.demo.do.prometheus.io:9201/read
#     basic_auth:
#       password: FOO

prometheus_external_labels:
  environment: "{{ ansible_fqdn | default(ansible_host) | default(inventory_hostname) }}"

prometheus_targets:
  node:
    - targets:
        - 91.185.84.152:2379
      labels:
        env: test

prometheus_scrape_configs:
  - job_name: "prometheus"
    metrics_path: "{{ prometheus_metrics_path }}"
    static_configs:
      - targets:
          - "{{ ansible_fqdn | default(ansible_host) | default('localhost') }}:9090"
  - job_name: "node"
    file_sd_configs:
      - files:
          - "{{ prometheus_config_dir }}/file_sd/node.yml"
  - job_name: "etcd"
    file_sd_configs:
      - files:
        - "{{ prometheus_config_dir }}/file_sd/etcd.yml"
  - job_name: "node_exporter"
    file_sd_configs:
      - files:
        - "{{ prometheus_config_dir }}/file_sd/node_exporter.yml"
  - job_name: "black_box"
    file_sd_configs:
      - files:
        - "{{ prometheus_config_dir }}/file_sd/black_box.yml"
  - job_name: "patroni_exporter"
    file_sd_configs:
      - files:
        - "{{ prometheus_config_dir }}/file_sd/patroni_exporter.yml"
  - job_name: "postgres_exporter"
    file_sd_configs:
      - files:
        - "{{ prometheus_config_dir }}/file_sd/postgres_exporter.yml"

prometheus_blackbox_configs:
  - job_name: blackbox
    metrics_path: /probe
    params:
      module: [ http_2xx ]
    static_configs:
      - targets:
          - http://weather-forecast.ddns.net/Cities
    relabel_configs:
      - source_labels: [ __address__ ]
        target_label: __param_target
      - source_labels: [ __param_target ]
        target_label: instance
      - target_label: __address__
        replacement: localhost:9115

# Alternative config file name, searched in ansible templates path.
prometheus_config_file: 'prometheus.yml.j2'

prometheus_alert_rules_files:
  - prometheus/rules/*.rules

prometheus_static_targets_files:
  - prometheus/targets/*.yml
  - prometheus/targets/*.json

# yamllint disable rule:line-length
prometheus_alert_rules:  # noqa yaml[line-length]  # noqa line-length
  - alert: Watchdog
    expr: vector(1)
    for: 10m
    labels:
      severity: none
    annotations:
      description: "This is an alert meant to ensure that the entire alerting pipeline is functional.\nThis alert is always firing, therefore it should always be firing in Alertmanager\nand always fire against a receiver. There are integrations with various notification\nmechanisms that send a notification when this alert is not firing. For example the\n\"DeadMansSnitch\" integration in PagerDuty."
      summary: 'Ensure entire alerting pipeline is functional'

  - alert: InstanceDown
    expr: 'up == 0'
    for: 5m
    labels:
      severity: critical
    annotations:
      description: '{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.{% endraw %}'
      summary: '{% raw %}Instance {{ $labels.instance }} down{% endraw %}'

  - alert: PatroniHasNoLeader
    expr: (max by (scope) (patroni_master) < 1)
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Patroni has no Leader (instance {{ $labels.instance }}){% endraw %}'
      description: '{% raw %}A leader node (neither primary nor standby) cannot be found inside the cluster {{ $labels.scope }}\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }} {% endraw %}'

  - alert: PostgresqlExporterError
    expr: pg_exporter_last_scrape_error > 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Postgresql exporter error (instance {{ $labels.instance }}){% endraw %}'
      description: '{% raw %} Postgresql exporter is showing errors. A query may be buggy in query.yaml\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }} {% endraw %}'
  - alert: EtcdInsufficientMembers
    expr: count(etcd_server_id) % 2 == 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Etcd insufficient Members (instance {{ $labels.instance }}){% endraw %}'
      description: '{% raw %}Etcd cluster should have an odd number of members\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}{% endraw %}'

  - alert: EtcdNoLeader
    expr: etcd_server_has_leader == 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Etcd no Leader (instance {{ $labels.instance }}){% endraw %}'
      description: '{% raw %}Etcd cluster have no leader\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}{% endraw %}'

  - alert: BlackboxProbeSlowHttp
    expr: avg_over_time(probe_http_duration_seconds[1m]) > 1
    for: 1m
    labels:
     severity: warning
    annotations:
     summary: '{% raw %}Blackbox probe slow HTTP (instance {{ $labels.instance }}){% endraw %}'
     description: '{% raw %}HTTP request took more than 1s\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}{% endraw %}'

  - alert: BlackboxProbeHttpFailure
    expr: probe_http_status_code != 200
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Blackbox probe HTTP failure (instance {{ $labels.instance }}){% endraw %}'
      description: '{% raw %}HTTP status code is not 200\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}{% endraw %}'

  - alert: BlackboxProbeFailed
    expr: probe_success == 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Blackbox probe failed (instance {{ $labels.instance }}){% endraw %}'
      description: '{% raw %}Probe failed\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}{% endraw %}'

  - alert: NodeExporterHostOutOfMemory
    expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: '{% raw %}Host out of memory (instance {{ $labels.instance }}){% endraw %}'
      description: '{% raw %}Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}{% endraw %}'

  - alert: NodeExporterHostOutOfDiskSpace
    expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: '{% raw %}Host out of disk space (instance {{ $labels.instance }}){% endraw %}'
      description: '{% raw %}Disk is almost full (< 10% left)\n  VALUE = {{ $value }}{% endraw %}'

  - alert: NodeExporterHostHighCpuLoad
    expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100) > 80
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: '{% raw %}Host high CPU load (instance {{ $labels.instance }}){% endraw %}'
      description: '{% raw %}CPU load is > 80%\n  VALUE = {{ $value }}{% endraw %}'

prometheus_stop_timeout: '600s'
